# -*- coding: utf-8 -*-
"""æ¡ç”¨èª²é¡Œï¼7ï¼¿æœ€çµ‚ãƒ¢ãƒ‡ãƒ«.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L6cDH5LpUzPnfrVbEUL3XeJLax-GUtvv

# æ¡ç”¨èª²é¡Œã€€æå‡ºç”¨ãƒ¢ãƒ‡ãƒ«

## æº–å‚™
"""

#!pip install wandb

import wandb

wandb.login()

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torchvision import datasets, transforms, models
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torchvision.models import resnet50
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
import seaborn as sns
from torchvision.models import ResNet50_Weights
#import torchvision.transforms.functional as TF
from torch.optim.lr_scheduler import CosineAnnealingLR

import random
import os

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

"""ä»¥ä¸‹ã§ã€ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã®å›ºå®šã‚’è¡Œã†ã€‚
ã‚·ãƒ¼ãƒ‰å€¤ã¯ï¼”ï¼’ã¨ã™ã‚‹ã€‚

æœ€å¾Œã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æŒ‡ç¤ºï¼š

deterministicã¯è¨ˆç®—ã®é †ç•ªã‚’å›ºå®šåŒ–ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã®ã‚ºãƒ¬ã‚’ãªãã™ã¨ã„ã†ã‚‚ã®ã€‚å†ç¾æ€§ã‚’é«˜ã‚ã‚‹

benchmarkã¯è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å›ºå®šåŒ–ã™ã‚‹ã‚‚ã®ã€‚ã“ã¡ã‚‰ã‚‚å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ã€‚
"""

device = "cuda" if torch.cuda.is_available() else "cpu"

device

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸€è¦§
# ã“ã®éƒ¨åˆ†ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€ãƒã‚¤ãƒ‘ãƒ©ã‚’å¤‰æ›´ã§ãã¾ã™ã€‚

config = {
    "learning_rate":1e-4,
    "batch_size": 256,
    "epochs": 12,
    "weight_decay": 1e-4,
    "architecture": "ResNet50",
    "dataset": "CIFAR-10",
    "optimizer": "Adam",
    "augmentation": "flip,crop,rotate",
    "note": "å…¨å±¤FTï¼‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©"
}

wandb.init(
    project="cifar10-resnet",
    name="model_for_submission6",
    config=config
)

"""## ç”»åƒãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

ã¾ãšã“ã“ã§ã€ãƒ‡ãƒ¼ã‚¿ã®æ‹¡å¼µã‚’è¡Œã£ã¦ã€éå­¦ç¿’ã‚’æŠ‘ãˆã‚‹å‡¦ç½®ã‚’è¡Œã†ã€‚
ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«é•ã†åŠ å·¥ãŒãªã•ã‚Œã‚‹ã“ã¨ã«ã‚ˆã‚Šã€æ±åŒ–æ€§èƒ½ãŒä¸ŠãŒã‚‹

valãƒ‡ãƒ¼ã‚¿ã®æ–¹ãŒæ­£è§£ç‡ãŒé«˜ããªã£ãŸã“ã¨ã‹ã‚‰ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã—ãŸç”»åƒãŒå­¦ç¿’ã™ã‚‹ã«ã¯é›£ã—ã™ããŸã¨ã„ã†ã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã®ã§ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®ç¨‹åº¦ã‚’å°‘ã—å¼±ã‚ã‚‹

transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),ã‚’å‰Šé™¤ã€‚paddingã‚’ï¼”â†’ï¼“ã¸ã€Rotationã‚’10â†’ï¼•ã¸

**è»¢ç§»å­¦ç¿’ã‚’å°å…¥ã™ã‚‹**

ãã®ãŸã‚ã«å‰å‡¦ç†ã§ç”»åƒã‚’224ã«ãƒªã‚µã‚¤ã‚ºã™ã‚‹ã€‚è§£åƒåº¦ã‚’ç„¡ç†ã‚„ã‚Šã‚ã’ã‚‹ã€‚

ãªãœã‹ã¨ã„ã†ã¨ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ResNetã¯ImageNetã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚’ã¤ã‹ã£ã¦å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã®imagenetã®è§£åƒåº¦ãŒ224ã ã‹ã‚‰ã€‚

ï¼’ï¼’ï¼”ï¼Šï¼’ï¼’ï¼”ã®ç”»åƒã‚’åœ§ç¸®ã—ã¦ç‰¹å¾´é‡ã‚’ã¤ã‹ã‚“ã§ã„ã‚‹ã®ã§ã€ï¼“ï¼’ï¼Šï¼“ï¼’ã®ç”»åƒã‚’ãã®ã¾ã¾å…¥åŠ›ã™ã‚‹ã¨åœ§ç¸®ã•ã‚Œã™ãã¦ç‰¹å¾´ãŒã¤ã‹ã‚ãªã„äº‹æ…‹ã«é™¥ã‚Šã€ç²¾åº¦ãŒå‡ºãªã„ã€‚

ã•ã‚‰ã«ã€ç¾ä»£ã®å¤šãã®å†™çœŸã¯è§£åƒåº¦ãŒé«˜ã„ã®ã§ã€ã“ã¡ã‚‰ã®æ–¹ãŒã‚ˆã‚Šå®Ÿç”¨æ€§ã‚‚ã‚ã‚‹ã¨ã„ã†ç‚¹ã§ã€ã‚ˆã‚Šã‚ˆã„ã€‚

ã¾ãŸã€ResNet50ã¯ImageNetã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äº‹å‰å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã“ã§ã¯ç²¾åº¦ã‚’ä¸Šã’ã‚‹ãŸã‚ã«ã€ImageNetã®è‰²ã®å¹³å‡å€¤ã‚’ç”¨ã„ã¦æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚

ãã®æ­£è¦åŒ–ã‹ã‚‰ãšã‚Œã¦ã—ã¾ã†ã¨ã€å‡çµã®å ´åˆã¯ã†ã¾ãç²¾åº¦ãŒå‡ºãªã„ã®ã¯ç†è§£ã§ãã‚‹ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã‚‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­ã§ã‚ºãƒ¬ãŒã©ã‚“ã©ã‚“ä¼æ’­ã—ã¦ã—ã¾ã„å­¦ç¿’ã—ã¥ã‚‰ã„ã€‚

ãã®ãŸã‚ã€imagenetã®è‰²å¹³å‡å€¤ã‚’ç”¨ã„ã¦æ­£è¦åŒ–ã‚’è¡Œã†

è§£åƒåº¦ãŒé«˜ã„ã®ã§ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’256ã«ç¸®å°ã€‚ãƒ¡ãƒ¢ãƒªãŒã‚ªãƒ¼ãƒãƒ¼ã™ã‚‹ã®ã‚’é˜²ãã€‚

**å­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ããŸ**

ãªãœã‹èª¿ã¹ãŸã¨ã“ã‚ã€ãƒªã‚µã‚¤ã‚ºã‚’CPUã§ã‚„ã‚‹ã®ãŒé‡ãã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã„ãŸã£ã½ã„

ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’GPUã«ç§»ã™ã€‚ã•ã‚‰ã«ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ã‚­ãƒ¥ãƒ©ã‚·ãƒ¼ã®ã»ã†ãŒé«˜ã‹ã£ãŸã“ã¨ã‚’é‘‘ã¿ã¦å‰å‡¦ç†ã‚’æ¸›ã‚‰ã™ã€‚

**å‰å‡¦ç†ã¯é‡è¦ã ã£ãŸ**

ä¸Šè¨˜ã‚’ã—ã¦ã‚‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³accãŒä¼¸ã³ãªã‹ã£ãŸã€‚åˆ¥ã«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãŒé«˜ã„ã“ã¨ã¯ã€ãã“ã¾ã§æ‚ªã„ã“ã¨ã§ã¯ãªã„ãªã¨åçœã€‚å‰å‡¦ç†ã‚’ã‚‚ã¨ã«ã‚‚ã©ã™ã€‚

**ã•ã‚‰ã«æ‚ªåŒ–ã—ãŸ**

ãªã‚“ã§...ï¼Ÿå‰å‡¦ç†ã—ã¦ã‹ã‚‰ãƒªã‚µã‚¤ã‚ºã ã¨ä½•ãŒä½•ã ã‹åˆ†ã‹ã‚‰ãªããªã‚‹ã®ã‹ãªã€‚å›è»¢ãªã©ã®å‰å‡¦ç†ã‚‚GPUã«ä¹—ã›ã¦ã¿ã‚‹ã€‚
flipã¯ãƒªã‚µã‚¤ã‚ºå‰å¾Œã§å¤‰ã‚ã‚‰ãªã„ã®ã§ãã®ã¾ã¾ã€‚

**ã‚ã‚“ã¾ã‚Šå¤‰ã‚ã‚‰ãªã‹ã£ãŸ**
ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒåŸå› ãªã®ã‹ï¼Ÿ256ã«ã‚‚ã©ã™ã€‚
"""

val_transform = transforms.Compose([
    transforms.ToTensor(),
])

train_transform = transforms.Compose([
    transforms.ToTensor(),
])

train_dataset = datasets.CIFAR10(root="./data", train = True, download=True, transform = train_transform)
validation_dataset = datasets.CIFAR10(root="./data", train = False, download=True, transform = val_transform)

names = ("plane", "car", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck")

train_dataloader = DataLoader(train_dataset, batch_size = wandb.config.batch_size, shuffle=True, num_workers=2)
validation_dataloader = DataLoader(validation_dataset, batch_size = wandb.config.batch_size, shuffle=False, num_workers=2)

data_iter = iter(train_dataloader)

imgs, labels = next(data_iter)

labels

imgs.size()

img = imgs[0]

img_permute = img.permute(1,2,0)

mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])

img_show = img.permute(1, 2, 0).numpy() # HWCã«ã—ã¦numpyåŒ–
img_show = std * img_show + mean
img_show = np.clip(img_show, 0, 1)    # æœ€å¾Œã«0-1ã«åã‚ã‚‹

plt.imshow(img_show)

"""äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã™ã‚‹ã€‚

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã›ã‚‹ã€‚
"""

model = resnet50(weights=ResNet)

model.fc = nn.Linear(model.fc.in_features, 10)

"""

frozen_weights_path = "experiment_two-stage_base4.pth"

if os.path.exists(frozen_weights_path):
    print(f"ğŸ”„ Loading Best Seed from {frozen_weights_path}...")
    state_dict = torch.load(frozen_weights_path, map_location=device)
    model.load_state_dict(state_dict)
else:
    print("âš ï¸ Seed file not found!")

"""

print(model)

model.to(device)

"""weight_decayã¨ã„ã†ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ ã€‚

ã“ã‚Œã‚’è¡Œã†ã“ã¨ã§ã€ä¸€ç‚¹ã ã‘ã«é‡ã¿ãŒåã‚‹ã¿ãŸã„ãªã“ã¨ãŒãªã„ã‚ˆã†ã«ã€é‡ã¿ã‚’å¤§ããã—ãªã„ã§ã»ã—ã„ã¨ã„ã†æŠ‘åˆ¶ãŒã‹ã‹ã‚‹ã€‚

ãã†ã™ã‚‹ã¨ã€æœ¬å½“ã«é‡è¦ãªéƒ¨åˆ†ï¼ˆçŒ«ã®è€³ã¨ã‹ï¼‰ã«ã®ã¿é‡ã¿ãŒã¤ãã‚ˆã†ã«ãªã‚‹

éå­¦ç¿’æŠ‘åˆ¶ã®åŠ¹æœãŒæœŸå¾…ã§ãã‚‹ã€‚

"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate, weight_decay=wandb.config.weight_decay)
scheduler = CosineAnnealingLR(optimizer, T_max=wandb.config.epochs, eta_min=1e-6)

"""gpuã§å®Ÿè¡Œã™ã‚‹å‰å‡¦ç†ã‚’è¿½åŠ """

num_epochs = wandb.config.epochs

losses = []
accs = []
val_losses = []
val_accs = []

gpu_transform = nn.Sequential(
    transforms.Resize(224, antialias=True),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(5),
    transforms.RandomCrop(224, padding=3),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
).to(device)

# æ¤œè¨¼ç”¨
gpu_val_transform = nn.Sequential(
    transforms.Resize(224, antialias=True),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
).to(device)

for  epoch in range(num_epochs):
  model.train()
  running_loss = 0.0
  running_acc = 0.0
  for imgs, labels in  train_dataloader:
    imgs = imgs.to(device)
    labels = labels.to(device)

    imgs = gpu_transform(imgs)

    optimizer.zero_grad()
    output = model(imgs)
    loss = criterion(output, labels)
    loss.backward()
    running_loss += loss.item()
    pred = torch.argmax(output, dim=1)
    running_acc += torch.mean(pred.eq(labels).float())
    optimizer.step()

  scheduler.step()
  running_loss /= len(train_dataloader)
  running_acc /= len(train_dataloader)
  losses.append(running_loss)
  accs.append(running_acc)
#
#validation loop
#
  model.eval()
  val_running_loss = 0.0
  val_running_acc = 0.0

  all_preds = []
  all_labels = []
  misclassified_images = []

  for val_imgs, val_labels in validation_dataloader:
    val_imgs = val_imgs.to(device)
    val_labels = val_labels.to(device)

    val_imgs = gpu_val_transform(val_imgs)

    with torch.no_grad():
      val_output  = model(val_imgs)
      val_loss = criterion(val_output, val_labels)
    val_running_loss += val_loss.item()
    val_pred = torch.argmax(val_output, dim=1)
    val_running_acc += torch.mean(val_pred.eq(val_labels).float())
    all_preds.extend(val_pred.cpu().numpy())
    all_labels.extend(val_labels.cpu().numpy())

    # äºˆæ¸¬ã¨æ­£è§£ãŒé•ã†å ´æ‰€ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã‚’æ¢ã™
    mistakes = val_pred != val_labels

    # é–“é•ãˆãŸç”»åƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    mistake_indices = mistakes.nonzero(as_tuple=True)[0]

    # é–“é•ãˆãŸç”»åƒã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ ï¼ˆ32æšé›†ã¾ã£ãŸã‚‰çµ‚äº†ï¼‰
    if len(misclassified_images) < 32:
      for idx in mistake_indices:
        if len(misclassified_images) >= 32: break

        img = val_imgs[idx].cpu().permute(1, 2, 0).numpy()
        pred_label = names[val_pred[idx].item()]
        true_label = names[val_labels[idx].item()]

        img = std * img + mean
        img = np.clip(img, 0, 1)

        # W&Bç”¨ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã«ã—ã¦ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹
        misclassified_images.append(
        wandb.Image(img, caption=f"Pred: {pred_label}, True: {true_label}")
       )

  #precision,recall,f1ã®è¨ˆç®—
  precision, recall, f1, _ = precision_recall_fscore_support(
      all_labels, all_preds, average='macro', zero_division=0
  )

  #æ··åŒè¡Œåˆ—ä½œæˆ
  cm = confusion_matrix(all_labels, all_preds)
  fig, ax = plt.subplots(figsize=(8, 8))
  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=names, yticklabels=names, ax=ax)
  plt.xlabel('Predicted')
  plt.ylabel('True')
  plt.title(f'Confusion Matrix (Epoch {epoch+1})')

  current_lr = scheduler.get_last_lr()[0]

  cm_image = wandb.Image(fig)
  plt.close(fig)

  val_running_loss /= len(validation_dataloader)
  val_running_acc /= len(validation_dataloader)
  val_losses.append(val_running_loss)
  val_accs.append(val_running_acc)
  print("epoch: {}, loss: {}, acc:{}, \
  val loss: {}, val acc: {}, F1: {}".format(epoch+1, running_loss, running_acc, val_running_loss, val_running_acc, f1))

  wandb.log({
      "epoch":epoch + 1,
      "lr": current_lr,
      "acc": running_acc,
      "loss": running_loss,
      "val acc": val_running_acc,
      "val loss": val_running_loss,
      "val precision": precision,
      "val recall": recall,
      "val f1": f1,
      "confusion_matrix": cm_image,
      "Misclassified Examples": misclassified_images
      })

run_name = wandb.run.name.replace(" ", "_")

torch.save(model.state_dict(), f"{run_name}.pth")
wandb.save(f"{run_name}.pth")

"""##è©•ä¾¡

è©•ä¾¡æŒ‡æ¨™ã«ã¤ã„ã¦

ROC-AUCã¯å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã«ãŠã„ã¦èª¬æ˜ãŒç…©é›‘ã«ãªã‚‹ãŸã‚ã€ä»Šå›ã¯è¦‹é€ã‚Šã€‚
"""

plt.style.use("ggplot")
plt.plot(losses, label="train loss")
plt.plot(val_losses, label="validation loss")
plt.legend()

plt.plot([accs_.cpu() for accs_ in accs], label="train acc")
plt.plot([accs_.cpu() for accs_ in val_accs], label="validation acc")
plt.legend()

# 1. å…¨äºˆæ¸¬ã‚’é›†ã‚ã‚‹
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for imgs, labels in validation_dataloader:
        imgs = imgs.to(device)
        labels = labels.to(device)

        # â˜…ã“ã“ã«è¿½åŠ ï¼æ¤œè¨¼ç”¨ã®å‰å‡¦ç†ã‚’é€šã™
        imgs = gpu_val_transform(imgs)

        outputs = model(imgs)
        preds = torch.argmax(outputs, dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# 2. æ··åŒè¡Œåˆ—
cm = confusion_matrix(all_labels, all_preds)

plt.figure(figsize=(6, 6))
sns.heatmap(
    cm,
    annot=False,
    fmt="d",
    xticklabels=names,
    yticklabels=names,
)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix (baseline)")
plt.show()

# ãƒ‡ãƒ¼ã‚¿ã‚’CPUã«ç§»ã—ã¦ãƒªã‚¹ãƒˆåŒ–ï¼ˆå¿µã®ãŸã‚ï¼‰
train_acc_list = [x.item() if isinstance(x, torch.Tensor) else x for x in accs]
val_acc_list = [x.item() if isinstance(x, torch.Tensor) else x for x in val_accs]
train_loss_list = [x if isinstance(x, float) else x.item() for x in losses]
val_loss_list = [x if isinstance(x, float) else x.item() for x in val_losses]

epochs_range = range(1, len(train_acc_list) + 1)

plt.figure(figsize=(14, 5))

# --- ç²¾åº¦ (Accuracy) ã®æ¯”è¼ƒã‚°ãƒ©ãƒ• ---
plt.subplot(1, 2, 1)
plt.plot(epochs_range, train_acc_list, label='Train Acc', marker='o')
plt.plot(epochs_range, val_acc_list, label='Val Acc', marker='o')

# â˜…ã“ã“ãŒãƒã‚¤ãƒ³ãƒˆï¼šã‚®ãƒ£ãƒƒãƒ—ã‚’å¡—ã‚Šã¤ã¶ã™
plt.fill_between(epochs_range, train_acc_list, val_acc_list, where=[t > v for t, v in zip(train_acc_list, val_acc_list)],
                 color='red', alpha=0.1, label='Overfitting Gap')

plt.title('Accuracy: Train vs Val')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid(True)
plt.legend()

# --- æå¤± (Loss) ã®æ¯”è¼ƒã‚°ãƒ©ãƒ• ---
plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss_list, label='Train Loss', marker='o')
plt.plot(epochs_range, val_loss_list, label='Val Loss', marker='o')
plt.title('Loss: Train vs Val')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.grid(True)
plt.legend()

plt.show()

wandb.finish()